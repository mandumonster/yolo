## YOLO9000: 빠르고 정확한 객체 감지를 위한 혁신적인 방법

### 소개
- Object Detection: 빠르고 정확한 다양한 객체 감지가 필수적.
- 문제: 기존 기술은 작은 객체 집합에만 제한.
- 물체 감지 데이터셋 현황: 분류, 태깅 데이터셋에 비해 제한적.
- 주요 디텍션 데이터셋: 수백개 태그, 수십만 이미지 포함. 
- 분류 데이터셋: 수백만 이미지, 10-100개 카테고리.

### 도전과제
- 디텍션을 분류 수준으로 확장 필요.
- 이미지에 레이블 지정은 분류, 태그보다 비용이 많이 듦.

### 우리의 제안
1. **데이터 활용**: 대량의 분류 데이터를 활용하여 탐지 시스템의 범위 확장.
2. **계층적 접근**: 서로 다른 데이터셋을 효과적으로 결합하는 개체 분류의 계층적 접근 방법 도입.

### 핵심 아이디어
- 객체 탐지 및 분류 데이터에 대한 공동 훈련 알고리즘 도입.
- 레이블이 지정된 감지 이미지를 활용하여 객체 정확한 로컬라이즈.
- 분류 이미지를 활용하여 어휘 확장 및 모델 견고성 향상.

### 결과물
- YOLO9000: 9000가지 이상의 다양한 객체 범주를 감지 가능한 실시간 객체 감지기.
  
### 절차
1. 기본 YOLO 시스템 개선하여 YOLOv2 생성.
2. 데이터 세트 결합 방법 및 합동 훈련 알고리즘 활용하여 ImageNet, COCO 데이터로 모델 훈련.
3. 모든 코드 및 사전 훈련된 모델은 [여기](http://pjreddie.com/yolo9000/)에서 온라인으로 사용 가능.


## YOLOv2의 개선 (Better)

### 1. 도입
- YOLOv2는 빠르고 정확한 객체 감지를 목표로 하는데, 기존 기술은 작은 개체 집합에 제한되어 있다.

### 2. 단점 및 개선 방향
#### 2.1. 과거의 단점
- 위치 파악 오류 및 낮은 재현율
- 속도 유지하면서 정확도 향상 필요

#### 2.2. 성능 향상을 위한 전략
- 네트워크 단순화 및 효율화
- 다양한 아이디어 및 개념 결합

### 2-1. Batch Normalization
- YOLO의 합성곱 층에 배치 정규화 추가
- mAP에서 2% 이상 향상
- 과적합 방지 및 드롭아웃 제거

### 2-2. High Resolution Classifier
- ImageNet에서 448 × 448 해상도로 분류 네트워크 세밀하게 조정
- 감지 네트워크에 미치는 성능 향상으로 mAP에서 거의 4% 증가

### 2-3. Convolutional With Anchor Boxes
- Anchor Boxes 도입으로 바운딩 박스 예측 방식 변경
- 높은 해상도의 입력 이미지에 대한 조정으로 mAP에서 4% 증가
- 일부 정확도 감소, 그러나 리콜 증가로 모델의 더 많은 여지 확보

### 2-4. 차원 클러스터
- 앵커 박스 사용 시 수동 선택의 어려움과 모델의 불안정성 문제를 해결하기 위해 k-means 클러스터링 도입
- 평균 IOU를 고려하여 5개의 priors 선정
- 중심 위치 예측으로 더 안정적인 학습 가능성 및 약간의 성능 향상

### 2-5. 직접 위치 예측
- 상자 위치를 예측하는 부분에서 발생하는 모델 불안정성 대응
- 로지스틱 활성화와 그리드 셀 위치와 관련된 위치 좌표를 예측하여 안정적인 학습 및 약간의 성능 향상
- 바운딩 박스의 중심 위치를 직접 예측하면서 차원 클러스터 사용으로 앵커 박스 대비 거의 5% 성능 향상

### 2-6. 멀티-스케일 훈련
- 네트워크의 다양한 입력 크기에 대응하기 위한 멀티-스케일 훈련 전략 도입
- 320 × 320에서 608 × 608까지 무작위로 선택하여 훈련, 다양한 해상도에서 감지 예측으로 모델 안정성 및 다양한 환경 대응 향상
- 낮은 해상도에서는 빠르면서도 정확한 감지기로, 고해상도에서 최첨단 성능 제공

### 2-6. 추가 실험
- VOC 2012 및 COCO 데이터셋에서 YOLOv2 성능 확인
- VOC 2012에서 78.6 mAP로 최첨단 탐지기로 평가되며 실시간 속도 유지
- COCO에서는 다른 방법과 유사한 성능을 보여주며, VOC 지표에서는 44.0 mAP를 기록하여 높은 정확도 제공

## 결과
- 기존 YOLO보다 정확한 객체 감지, 높은 성능 유지
- 빠른 속도, 더 간결한 모델 구조
- [온라인에서 사용 가능한 코드 및 사전 훈련된 모델](http://pjreddie.com/yolo9000/)
**결과적으로 YOLOv2는 차원 클러스터, 직접 위치 예측, 멀티-스케일 훈련 등을 통해 안정적이고 뛰어난 성능을 달성함.**

## 3. YOLOv2의 빠른 감지 (Faster)

### Faster Design Philosophy
- 정확성 뿐만 아니라 낮은 지연 예측 모델을 지향하여 빠른 감지 필요
- VGG-16의 복잡성 대신 Googlenet 아키텍처를 기반으로 한 Darknet-19 도입
- Darknet-19은 VGG-16보다 빠르면서도 상위 5 정확도 88.0%로 유사한 성능 제공

### Darknet-19 Architecture
- 3 × 3 필터 주로 사용하며, 매 풀링 단계마다 채널 수를 두 배로 늘리는 구조
- Network in Network (NIN)에서 영감 받아 글로벌 평균 풀링과 1 × 1 필터 사용
- 배치 정규화로 훈련 안정화 및 수렴 속도 향상

### Training for Classification
- ImageNet 1000 클래스 분류 데이터셋에서 Darknet-19 훈련
- 확률적 경사 하강법, 다항식 학습률 감소, 배치 정규화 등 사용
- 데이터 증강 기법 적용하여 미세 조정, 상위 5 정확도 93.3% 달성

### Training for Detection
- 탐지를 위해 네트워크 수정: 출력 수 조정 및 패스스루 레이어 추가
- VOC의 경우 5개의 좌표와 20개의 클래스를 예측하는 125개의 필터 필요
- 패스스루 레이어 추가로 미세한 특징 활용 가능
- COCO와 VOC에서 동일한 훈련 전략 사용

**결과적으로 YOLOv2는 Darknet-19를 통해 빠른 감지를 위한 높은 성능을 유지함.**


## **4. 강화된 모델**

- **공동 훈련:** 분류 및 탐지 데이터에 대한 공동 훈련 제안
- **도전 과제:** 상호 배타적 클래스와 다양한 데이터셋 통합 어려움

### **4-1. 계층적 분류**

- **데이터셋 및 WordNet 활용:**
  - WordNet을 사용한 데이터셋
  - 언어의 복잡성으로 트리 대신 방향 그래프 활용
  - "개"는 "canine" 및 "domestic animal"과 연결된 동의어 집합(synset)의 예시

- **계층적 트리 구축:**
  - ImageNet 시각적 명사를 기반으로 WordNet 그래프의 루트인 "physical object"까지 경로 검토
  - 하나의 경로만 가지는 동의어 집합을 트리에 추가
  - 최소한의 확장 경로 추가

- **WordTree 모델:**
  - 각 노드에서 하위어의 조건부 확률 예측
  - 예: "terrier" 노드에서
    - P r(Norfolk terrier|terrier)
    - P r(Yorkshire terrier|terrier)
    - P r(Bedlington terrier|terrier)

- **절대 확률 계산:**
  - 루트 노드까지의 경로를 따라가서 조건부 확률을 곱하여 특정 노드에 대한 절대 확률 계산
  - 예: P r(Norfolk terrier) = P r(Norfolk terrier|terrier) * P r(terrier|hunting dog) * ... * P r(mammal|P r(animal) * P r(animal|physical object)

- **훈련 및 성능:**
  - Darknet-19 모델을 WordTree로 훈련
  - 1369개의 클래스에 대한 트리 구조 예측
  - 369개의 추가 개념 추가
  - 71.9%의 top-1 정확도, 90.4%의 top-5 정확도 달성
  - 새로운 객체에 우아하게 저하되는 성능

- **감지 및 트리 활용:**
  - YOLOv2의 물체 존재 예측기 사용
  - 바운딩 박스 및 가능성 트리 예측
  - 트리를 아래로 이동하면서 가장 높은 확신 경로 선택
  - 일정 임계값에 도달하면 해당 객체 클래스 예측

- **이점 및 감지 활용:**
  - 새로운 객체 카테고리에 대해 우아한 저하
  - 하위어 간 낮은 신뢰도 분산
  - YOLOv2의 물체 존재 예측기를 통한 감지 수행

### **4-2. WordTree를 활용한 데이터셋 결합:**
- WordTree로 다양한 데이터셋 효과적 결합 가능

### **4-3. 통합 분류 및 탐지 학습**

- **데이터셋 통합:**
  - COCO 탐지 데이터셋과 전체 ImageNet 릴리스의 상위 9000 클래스를 결합하여 대규모 탐지기 훈련
  - ImageNet 클래스 부족 시 추가

- **WordTree 대응:**
  - 해당 데이터셋에 대응하는 WordTree에는 9418개 클래스 포함
  - COCO를 ImageNet과 균형을 맞추기 위해 과잉 샘플링

- **모델 아키텍처:**
  - YOLO9000 모델 사용
  - YOLOv2 기반, 3개 priors 사용하여 출력 크기 제한

- **학습 및 역전파:**
  - 감지 이미지의 경우 일반적인 손실 역전파 진행
  - 분류 손실은 해당 클래스 수준 이상에서만 역전파
  - 하위 예측 오류는 전파하지 않음

- **성능 평가:**
  - YOLO9000은 COCO 탐지 데이터를 사용하여 객체 탐지 및 ImageNet 데이터를 사용하여 객체 분류 학습
  - ImageNet 탐지 작업에서 19.7 mAP 달성, 새로운 객체 클래스에 대해서도 16.0 mAP
  - 9000개 객체 범주를 실시간으로 감지하며, DPM보다 뛰어난 결과 도출

- **성능 분석:**
  - 새로운 동물 종은 COCO의 동물에서 objectness 예측이 잘 일반화되어 더 쉽게 학습
  - 일부 범주(의류 및 장비)에 대한 학습 어려움 존재
  - 다양한 객체 범주에서도 우수한 성능 발휘
